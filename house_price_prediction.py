# -*- coding: utf-8 -*-
"""House Price Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mr2KDLBw_TqtVt3tGfyreq71eAlkCqk4
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics

# Importing the California House Price Dataset
house_price_dataset = fetch_california_housing()

# Pandas DataFrame
house_price_dataframe = pd.DataFrame(house_price_dataset.data, columns=house_price_dataset.feature_names)

# Adding target price column into DataFrame
house_price_dataframe['price'] = house_price_dataset.target

# Print the first 5 rows of our DataFrame
print(house_price_dataframe.head())

# No. of rows and columns in the DataFrame
print("Shape of DataFrame:", house_price_dataframe.shape)

# Check for missing values
print("Missing values:\n", house_price_dataframe.isnull().sum())

# Statistical measures of the dataset
print("Statistical summary:\n", house_price_dataframe.describe())

# Understanding the correlation between various features in the dataset
correlation = house_price_dataframe.corr()

# Constructing a heatmap to understand the correlation
plt.figure(figsize=(10, 10))
sns.heatmap(
    data=correlation,
    cmap='Blues',
    annot=True,
    fmt='.1f',
    cbar=True,
    square=True,
    annot_kws={'size': 8})
plt.title('Feature Correlation Heatmap')
plt.show()

# Splitting data into features and target
X = house_price_dataframe.drop(['price'], axis=1)
Y = house_price_dataframe['price']

print("Features:\n", X.head())
print("Target:\n", Y.head())

# Splitting data into training and test sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print("Feature shape:\n", X.shape)
print("Training feature shape:\n", X_train.shape)
print("Test feature shape:\n", X_test.shape)

# Model Training with XGBoost Regressor
model = XGBRegressor()

# Training the model with X_train
model.fit(X_train, Y_train)

# Evaluation on training data
training_data_prediction = model.predict(X_train)

# R squared error and Mean Absolute Error on training data
score_r2_train = metrics.r2_score(Y_train, training_data_prediction)
score_mae_train = metrics.mean_absolute_error(Y_train, training_data_prediction)

print("Training Data - R squared error:", score_r2_train)
print("Training Data - Mean Absolute Error:", score_mae_train)

# Visualization of actual Prices and predicted prices
plt.scatter(Y_train, training_data_prediction)
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual Prices vs Predicted Prices (Training Data)")
plt.show()

# Prediction on Test Data
test_data_prediction = model.predict(X_test)

# R squared error and Mean Absolute Error on test data
score_r2_test = metrics.r2_score(Y_test, test_data_prediction)
score_mae_test = metrics.mean_absolute_error(Y_test, test_data_prediction)

print("Test Data - R squared error:", score_r2_test)
print("Test Data - Mean Absolute Error:", score_mae_test)